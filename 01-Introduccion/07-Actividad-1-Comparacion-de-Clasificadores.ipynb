{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"position: relative; text-align: center; padding: 30px;\">\n",
    "  <h1><strong>Comparasión de Clasificadores</strong></h1>\n",
    "  <h3><strong>Walter y Heri</strong></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** El objetivo de esta actividad es que cada equipo cree una función que permita manejar diferentes formas de representación de clasificaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instrucciones:**\n",
    "- Construye una clase en Python que reciba una clasificación en representación vectorial, y construya la representación matricial y de conjunto de conjuntos de la clasificación. Haz un método para cada conversión:  \n",
    "    - vectorial -> matricial.  \n",
    "    - vectorial -> conjunto de conjuntos.  \n",
    "- Guarda las tres representaciones como variables ocultas usando la nomenclatura \"__parameter\".  \n",
    "- Crea tres métodos getter para devolver cada representación.  \n",
    "- Construye un método para calcular los siguientes valores:  \n",
    "    - Entropía de una clasificación.  \n",
    "    - La entropía condicional de una clasificación dada otra clasificación.  \n",
    "    - La información mutua de una clasificación dada otra clasificación.  \n",
    "    - La variación de información de una clasificación dada otra clasificación.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class comparacion_de_clasificadores:\n",
    "\n",
    "    def __init__(self, vector):\n",
    "        # Para agregar la funcionalidad de manejar un segundo vector opcional en la clase,\n",
    "        # puedes modificar el constructor para aceptar un segundo vector\n",
    "        # y ajustar los métodos para que manejen este vector cuando esté presente. - Chat\n",
    "        \n",
    "        # Lo quiero para probabilidades conjuntas y condicionales\n",
    "\n",
    "        # Queria poner dos pero no va a dar tiempo D:\n",
    "\n",
    "        self.__vector = vector\n",
    "\n",
    "        self.__labels = self.get_labels()\n",
    "        self.__probabilities = self.get_probabilities()\n",
    "        self.__matrix = self.create_matrix()\n",
    "        self.__sets = self.create_sets()\n",
    "\n",
    "    def create_matrix(self):\n",
    "        # Create an empty matrix\n",
    "        matrix = []\n",
    "        for row in range(len(self.__vector)): # for each label in the vector\n",
    "            matrix.append([0] * len(self.__labels)) # add a row of zeros\n",
    "\n",
    "        # Fill the matrix\n",
    "        for label in range(len(self.__vector)): # for each label in the vector\n",
    "\n",
    "            matrix[label][self.__labels.index(self.__vector[label])] = 1 # set the value to 1\n",
    "            # labels.index(self.__vector[label]) returns the index of the label in the labels list\n",
    "\n",
    "        return matrix\n",
    "    \n",
    "\n",
    "    def create_sets(self):\n",
    "        # Create a dictionary of sets        \n",
    "        conjuntos = {} \n",
    "        for i, elemento in enumerate(self.__vector):  \n",
    "            if elemento not in conjuntos:\n",
    "                conjuntos[elemento] = set()\n",
    "            conjuntos[elemento].add(i) \n",
    "\n",
    "        lista_de_conjuntos = list(conjuntos.values())\n",
    "\n",
    "        return lista_de_conjuntos\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # ---\n",
    "    # Crea tres métodos getter para devolver cada representación. \n",
    "\n",
    "    def get_vector(self):\n",
    "        return self.__vector\n",
    "    \n",
    "    def get_matrix(self):\n",
    "        return self.__matrix\n",
    "    \n",
    "    def get_sets(self):\n",
    "        return self.__sets\n",
    "    \n",
    "    # Las usamos mucho, entonces las guardamos en variables\n",
    "\n",
    "    # Funcion para obtener las etiquetas diferentes de un vector\n",
    "    def get_labels(self):\n",
    "        labels = []\n",
    "        for label in self.__vector:\n",
    "            if label not in labels:\n",
    "                labels.append(label)\n",
    "        return labels\n",
    "    \n",
    "\n",
    "    # Funcion para obtener las probabilidades de las etiquetas de un vector\n",
    "    def get_probabilities(self):\n",
    "        probabilities = [] \n",
    "        for label in self.__labels:\n",
    "            probability = self.__vector.count(label) / len(self.__vector) # |y_i| / N\n",
    "            probabilities.append(probability)\n",
    "        return probabilities\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # ---\n",
    "    # Construye un método para calcular los siguientes valores:\n",
    "\n",
    "    # - Entropía de una clasificación.\n",
    "    def entropy(self):\n",
    "        entropy = 0\n",
    "        for prob in self.__probabilities:\n",
    "            # lim_{p -> 0} p log_2(p) = 0\n",
    "            if prob != 0:\n",
    "                entropy += -prob * np.log2(prob)\n",
    "            else:\n",
    "                entropy += 0\n",
    "\n",
    "        print(\"Probabilities:\", self.__probabilities, \"Entropy:\", entropy)\n",
    "\n",
    "        return entropy\n",
    "    \n",
    "\n",
    "    # - La entropía condicional de una clasificación dada otra clasificación\n",
    "\n",
    "\n",
    "    def conditional_entropy(self, other):\n",
    "\n",
    "        # # Get unique values\n",
    "        # unique_x = list(set(self.__vector))\n",
    "        # unique_y = list(set(other))\n",
    "\n",
    "        # # Compute joint probability p(y, x)\n",
    "        # joint_prob = { (x, y): 0 for x in unique_x for y in unique_y }\n",
    "\n",
    "        # for i in range(len(self.__vector)):\n",
    "        #     joint_prob[(self.__vector[i], other[i])] += 1\n",
    "\n",
    "\n",
    "        # # Compute marginal probability p(x)\n",
    "        # p_x = { x: 0 for x in unique_x }\n",
    "        # for x, y in joint_prob:\n",
    "        #     p_x[x] += joint_prob[(x, y)]\n",
    "\n",
    "        # # Compute conditional entropy H(Y|X)\n",
    "        # conditional_entropy = 0\n",
    "        # for (x, y), p_xy in joint_prob.items():\n",
    "        #     if p_xy > 0 and p_x[x] > 0:\n",
    "        #         p_y_given_x = p_xy / p_x[x]\n",
    "        #         conditional_entropy += -p_xy * np.log2(p_y_given_x)\n",
    "\n",
    "        entropy = self.entropy()\n",
    "        mutual_information = self.mutual_information(other)\n",
    "\n",
    "        conditional_entropy = entropy - mutual_information\n",
    "\n",
    "        return conditional_entropy\n",
    "\n",
    "\n",
    "\n",
    "        # Conditional probabilities\n",
    "        #\n",
    "        # Y = {{}, {1, 2, 3, 4}, {   5, 6, 7, 8}}\n",
    "        # Y'= {{}, {   2, 3, 4}, {1, 5, 6, 7, 8}}\n",
    "        # \n",
    "        # P(Y'=1|Y=1) = 3/4\n",
    "        # P(Y'=2|Y=1) = 1/4\n",
    "        # \n",
    "        # La suma de los de arriba da 1\n",
    "        #\n",
    "        # P(Y'=1|Y=2) = 0\n",
    "        # P(Y'=2|Y=2) = 1\n",
    "\n",
    "        # Son las etiquetas que tenemos    \n",
    "\n",
    "    # - La información mutua de una clasificación dada otra clasificación.\n",
    "    def mutual_information(self, other):\n",
    "\n",
    "        # Intersection between the two classifications\n",
    "        intersection = []\n",
    "        for i in range(len(self.__vector)):\n",
    "            if self.__vector[i] == other[i]:\n",
    "                intersection.append(self.__vector[i])\n",
    "\n",
    "        # Calculate p(l) and p(l')\n",
    "        probabilities = []\n",
    "        for label in self.__labels:\n",
    "            probability = self.__vector.count(label) / len(self.__vector)\n",
    "            probabilities.append(probability)\n",
    "\n",
    "        other_probabilities = []\n",
    "        for label in self.__labels:\n",
    "            probability = other.count(label) / len(other)\n",
    "            other_probabilities.append(probability)\n",
    "\n",
    "        # Calculate joint probabilities P(l, l') for every pair (l, l')\n",
    "        joint_probabilities = {}  # Usamos un diccionario con clave (l, l'),  es un diccionario porque es más fácil de manejar \n",
    "        for i, label in enumerate(self.__labels): # Para cada etiqueta en el vector \n",
    "            for j, other_label in enumerate(self.__labels): # Para cada etiqueta en el otro vector\n",
    "                count = 0 # Contador de veces que aparece la etiqueta en ambos vectores\n",
    "                for k in range(len(self.__vector)): # Para cada elemento en el vector\n",
    "                    if self.__vector[k] == label and other[k] == other_label: # Si el elemento en el vector es igual a la etiqueta y el elemento en el otro vector es igual a la otra etiqueta\n",
    "                        count += 1\n",
    "                joint_probabilities[(label, other_label)] = count / len(self.__vector) # Guardamos la probabilidad conjunta en el diccionario\n",
    "\n",
    "\n",
    "        # Calculate the mutual information\n",
    "        mutual_information = 0.0\n",
    "        for i, label in enumerate(self.__labels):\n",
    "            for j, other_label in enumerate(self.__labels):\n",
    "                p_joint = joint_probabilities[(label, other_label)]\n",
    "                # Solo se suma el término si p_joint > 0, para evitar log(0)\n",
    "                if p_joint > 0:\n",
    "                    mutual_information += p_joint * np.log2(p_joint / (probabilities[i] * other_probabilities[j]))\n",
    "\n",
    "\n",
    "        return mutual_information\n",
    "    \n",
    "    # - La variación de información de una clasificación dada otra clasificación. \n",
    "    def variation_of_information(self, other):\n",
    "        # VI(x, y) = H(y) + H(x) - 2I(y, x)\n",
    "        variation_of_information = self.entropy() + self.entropy() - 2 * self.mutual_information(other)\n",
    "\n",
    "        return variation_of_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = (1, 2, 2, 3, 3, 3, 4, 4, 4, 4)\n",
    "other =  (1, 1, 1, 1, 2, 2, 2, 3, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_class = comparacion_de_clasificadores(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.create_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas son el número de labels, y las filas el numero de patrones observados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.get_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0}, {1, 2}, {3, 4, 5}, {6, 7, 8, 9}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.create_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0}, {1, 2}, {3, 4, 5}, {6, 7, 8, 9}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.get_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pone en el $y_1$ que son los patrones con etiqueta 1 los {3,4,5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.1, 0.2, 0.3, 0.4] Entropy: 1.8464393446710154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8464393446710154"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.entropy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.1, 0.2, 0.3, 0.4] Entropy: 1.8464393446710154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.conditional_entropy(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.1, 0.2, 0.3, 0.4] Entropy: 1.8464393446710154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.875488750216347"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.conditional_entropy(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8464393446710154"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.mutual_information(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the two classifications are equal, and only then, we have\n",
    "$$ I(y,y') = H(y)= H(y')$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546685"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.mutual_information(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.1, 0.2, 0.3, 0.4] Entropy: 1.8464393446710154\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "comparacion_de_clasificadores.entropy() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmy_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariation_of_information\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 203\u001b[0m, in \u001b[0;36mcomparacion_de_clasificadores.variation_of_information\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariation_of_information\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# VI(x, y) = H(y) + H(x) - 2I(y, x)\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     variation_of_information \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentropy() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutual_information(other)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m variation_of_information\n",
      "\u001b[1;31mTypeError\u001b[0m: comparacion_de_clasificadores.entropy() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "my_class.variation_of_information(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 1): 0.1, (2, 1): 0.2, (3, 1): 0.1, (3, 2): 0.2, (4, 2): 0.1, (4, 3): 0.2, (4, 4): 0.1}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vector = (1, 2, 2, 3, 3, 3, 4, 4, 4, 4)\n",
    "other =  (1, 1, 1, 1, 2, 2, 2, 3, 3, 4)\n",
    "\n",
    "# Contar las ocurrencias de cada par (l, l')\n",
    "pairs = list(zip(vector, other))\n",
    "pair_counts = Counter(pairs)\n",
    "\n",
    "# Calcular la probabilidad conjunta p(l, l')\n",
    "total_pairs = len(pairs)\n",
    "joint_probabilities = {pair: count / total_pairs for pair, count in pair_counts.items()}\n",
    "\n",
    "print(joint_probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
