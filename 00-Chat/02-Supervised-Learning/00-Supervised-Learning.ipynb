{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQG0GQWVq36n"
      },
      "source": [
        "<div style=\"position: relative; text-align: center; padding: 30px;\">\n",
        "  <h1><strong>Supervised Learning</strong></h1>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Supervised learning** is a type of machine learning where a model is trained using labeled data, meaning each input in the dataset is paired with a corresponding output or label. The goal is to learn a mapping function $f: \\mathcal{X} \\to \\mathcal{Y}$ that can predict the correct output $y$ for any given input $x$. Supervised learning is widely used in tasks such as classification, where the output is a discrete label (e.g., \"spam\" or \"not spam\"), and regression, where the output is a continuous value (e.g., predicting house prices). By minimizing the error between predicted and actual outputs, supervised learning models aim to generalize well to unseen data, making them essential for solving real-world problems like fraud detection, image recognition, and sentiment analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOUcszZiq50j"
      },
      "source": [
        "### **Learning a class from examples**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us say we want to learn the class, $C$, of a sedan car. We start with a **set of examples** of various cars and conduct a survey where people examine these cars and **label them**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Clases*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En **supervised learning** (aprendizaje supervisado), una **clase** es una categoría o etiqueta que se asigna a un conjunto de datos en el proceso de **entrenamiento**. Es el valor que el modelo intenta predecir a partir de las características o atributos de los datos de entrada.\n",
        "\n",
        "**Definición formal:**\n",
        "- En un **problema de clasificación**, los datos de entrada ($x$) están asociados con una etiqueta de clase $y$, que puede ser un valor discreto (como \"spam\" o \"no spam\", \"enfermo\" o \"sano\", etc.). \n",
        "- El modelo aprende a mapear las características de entrada ($x$) a la clase correspondiente ($y$).\n",
        "\n",
        " **Ejemplo:**\n",
        "Supongamos que estás entrenando un modelo para clasificar correos electrónicos como \"spam\" o \"no spam\". En este caso:\n",
        "- **Características**: El contenido del correo, el remitente, la hora de envío, etc.\n",
        "- **Clase**: Las clases posibles son **spam** y **no spam**. Cada correo electrónico tendrá una etiqueta asociada que es su clase (ya sea \"spam\" o \"no spam\").\n",
        "\n",
        " **Tipos de clases:**\n",
        "1. **Clases binarias (Clasificación binaria)**: Solo hay dos posibles clases. Ejemplos:\n",
        "   - **Spam vs No spam**.\n",
        "   - **Enfermo vs Sano**.\n",
        "2. **Clases multiclase**: Hay más de dos posibles clases. Ejemplos:\n",
        "   - **Clasificación de animales**: Perro, Gato, Caballo.\n",
        "   - **Clasificación de géneros musicales**: Pop, Rock, Jazz, etc.\n",
        "3. **Clases ordinales**: Las clases tienen un orden natural, pero las distancias entre ellas no son necesariamente iguales. Ejemplos:\n",
        "   - **Nivel de educación**: Primaria, Secundaria, Universitaria.\n",
        "   - **Clasificación de satisfacción**: Muy insatisfecho, Insatisfecho, Neutral, Satisfecho, Muy satisfecho.\n",
        "\n",
        " **¿Cómo se usan las clases en el entrenamiento?**\n",
        "Durante el entrenamiento, el modelo recibe ejemplos etiquetados (conjunto de entrenamiento) que contienen:\n",
        "- Las características ($x_1, x_2, \\dots, x_n$) de los datos.\n",
        "- Las clases asociadas $y_1, y_2, \\dots, y_n$ que son las etiquetas correctas.\n",
        "\n",
        "El modelo ajusta sus parámetros para aprender a predecir las clases correctas a partir de las características, minimizando el error entre las predicciones y las clases reales.\n",
        "\n",
        " **Resumen:**\n",
        "En resumen, una **clase** en **supervised learning** es el valor o etiqueta discreta que se asigna a un conjunto de datos y que el modelo intenta predecir. Estas clases son fundamentales en problemas de **clasificación**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjb0bVlaq9s3"
      },
      "source": [
        "Those cars that participants believe fit the characteristics of a sedan are marked as **positive examples**, while all other cars are marked as **negative examples**.\n",
        "\n",
        "The goal of **class learning** is to derive a **description** that **applies** to all positive examples and **excludes** all negative examples.\n",
        "\n",
        "With this description, we can **make predictions**: when presented with a new car, we can determine whether it is a sedan based on the learned description.\n",
        "\n",
        "After some discussions with experts in the field, let us say that we reach the conclusion that among all features a car may have, the **features that separate** a sedan car from other cars are the **price** and **engine power**. These two attributes are the **inputs** to the class recognizer.\n",
        "\n",
        "Note that when we decide on this particular **input representation**, we are ignoring various other attributes as irrelevant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guNM-1HDtFiI"
      },
      "source": [
        "Let us denote price as the first input attribute $x_1$ (e.g., in U.S. dollars) and size as the second attribute $x_2$ e.g., the car's length in meters). Thus we represent each car using the **feature vector**\n",
        "$$x = \\left[\\begin{matrix} x_1 \\\\ x_2 \\end{matrix} \\right]$$\n",
        "and its **label** denotes its type\n",
        "$$ r = \\begin{cases}1 \\qquad \\text{if $x$ is a positive example} \\\\ 0 \\qquad \\text{if $x$ is a negative example} \\end{cases}$$\n",
        "\n",
        "Each car is represented by such an ordered pair $(x, r)$ and the **training set** contains $N$ such examples\n",
        "$$X = \\{(x^i, r^i)\\}^N_{i=1}$$\n",
        "where $i$ indexes different examples in the set; it does not represent time or any such order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Chat*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8E2snPmr2PI"
      },
      "source": [
        " Ejemplo:\n",
        "\n",
        "Imagina que tienes un conjunto de coches y sus características:\n",
        "\n",
        "1. Coche 1:\n",
        "   - Precio $x_1 = 30,000$ USD\n",
        "   - Tamaño $x_2 = 4.5$ metros\n",
        "   - Etiqueta $r = 1$ (ejemplo positivo, por ejemplo, un coche de lujo)\n",
        "\n",
        "2. Coche 2:\n",
        "   - Precio $x_1 = 10,000$ USD\n",
        "   - Tamaño $x_2 = 3.8$ metros\n",
        "   - Etiqueta $r = 0$ (ejemplo negativo, por ejemplo, un coche económico)\n",
        "\n",
        "El conjunto de entrenamiento para estos dos ejemplos sería:\n",
        "\n",
        "$$\n",
        "X = \\left\\{\n",
        "\\left( \\left[\\begin{matrix} 30000 \\\\ 4.5 \\end{matrix} \\right], 1 \\right),\n",
        "\\left( \\left[\\begin{matrix} 10000 \\\\ 3.8 \\end{matrix} \\right], 0 \\right)\n",
        "\\right\\}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Índice arriba: $x^i$**\n",
        "\n",
        "Cuando se usa el índice en la parte superior, como en $x^i$, se suele indicar que el índice hace referencia a una **posición** dentro de un conjunto de objetos o un conjunto de entrenamiento. Esto es común en notaciones que involucran sumatorias o productos y tiene el sentido de \"el $i$-ésimo elemento\". También se utiliza en otros contextos como vectores o matrices, donde los exponentes pueden denotar alguna operación sobre el índice.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "- $x^i$ puede denotar el $i$-ésimo vector de características de un conjunto de entrenamiento.\n",
        "- $r^i$ puede denotar la etiqueta asociada al $i$-ésimo ejemplo.\n",
        "\n",
        "Es una forma muy común en matemáticas, especialmente cuando se habla de **conjuntos indexados**.\n",
        "\n",
        " 2. **Índice abajo: $x_i$**\n",
        "\n",
        "La notación con el índice en la parte inferior, como $x_i$, es más frecuente cuando se hace referencia a **componentes** de un vector o matriz. Esta notación es útil cuando quieres denotar el $i$-ésimo componente de un vector $x$, por ejemplo, el $i$-ésimo valor en el vector $x = [x_1, x_2, \\dots, x_n]$.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "- $x_i$ podría referirse al $i$-ésimo atributo de un vector de características (como el precio o tamaño de un coche, en tu ejemplo).\n",
        "- Si tienes un conjunto de datos $X = \\{x_1, x_2, \\dots, x_N\\}$, $x_i$ se refiere a las características del $i$-ésimo ejemplo.\n",
        "\n",
        " Diferencia clave entre $x^i$ y $x_i$:\n",
        "\n",
        "- **$x^i$**: Se refiere a la $i$-ésima **entidad completa** (por ejemplo, el vector de características completo del $i$-ésimo ejemplo). Es una forma más general y común en contextos de clasificación, redes neuronales, y conjuntos de entrenamiento.\n",
        "- **$x_i$**: Se refiere a la $i$-ésima **componente** del vector $x$. Se usa cuando estamos hablando de un vector y queremos denotar un componente específico dentro de ese vector.\n",
        "\n",
        "**Resumen:**\n",
        "\n",
        "- $x^i$ denota el $i$-ésimo **elemento o vector completo** del conjunto de entrenamiento.\n",
        "- $x_i$ denota el $i$-ésimo **componente** dentro de un vector o lista.\n",
        "\n",
        "Ambas notaciones son correctas, pero se usan en contextos distintos. En el caso que mencionabas, cuando estamos describiendo un conjunto de ejemplos de entrenamiento, se usa más comúnmente **el índice arriba** (como $x^i$) para indicar el $i$-ésimo ejemplo completo en el conjunto.\n",
        "\n",
        "\n",
        "Cuando escribimos $x^1$, estamos denotando el **primer vector de características** (o el primer ejemplo) en un conjunto de datos. Este vector de características, como mencionabas, está compuesto por varias componentes, por ejemplo, los atributos del coche: su precio, tamaño, etc.\n",
        "\n",
        "Entonces, si $x^1$ es el primer vector de características, podría representarse como:\n",
        "\n",
        "$$\n",
        "x^1 = \\left[ x_1, x_2, \\dots, x_n \\right]\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $x_1$ es el primer atributo (por ejemplo, el precio del coche).\n",
        "- $x_2$ es el segundo atributo (por ejemplo, el tamaño del coche).\n",
        "- Y así sucesivamente hasta $x_n$, que es el $n$-ésimo atributo de ese coche.\n",
        "\n",
        "Cada vector $x^i$ (como $x^1, x^2, \\dots, x^N$) representa un **ejemplo completo** de datos (es decir, todas las características de un coche) y tiene múltiples **componentes** dentro del vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk7Lu5lMuYrK"
      },
      "source": [
        "Our training data can now be plotted in the two-dimensional $(x_1, x_2)$ space where each instance $i$ is a data point at coordinates $$(x^i_\n",
        "1, x^i_2)$$ and its class, namely, positive versus negative, is given by $r^i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfvGQoThORBO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "jcXcMCO9OP1P",
        "outputId": "ed195bf9-5feb-44c1-bf56-7daebfac12cc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data = { # Create a dictionary\n",
        "    \"Price\":        [10, 11, 13, 15, 18, 9.8, 11.5, 12.5, 15, 12.5, 14, 14, 18.1, 18.5, 19], # Create a list of prices \n",
        "    \"Engine Power\": [9, 10, 9.6, 10.3, 7, 18, 15, 14, 16, 14.5, 15.5, 21, 20, 15, 14],\n",
        "    \"Class\":        [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"S\", \"S\", \"S\", \"S\", \"S\", \"O\", \"O\", \"O\", \"O\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.scatterplot(data=data, x=\"Price\", y=\"Engine Power\", hue=\"Class\",\n",
        "                palette=['blue', 'red'], s=100)\n",
        "handles, labels  =  ax.get_legend_handles_labels()\n",
        "ax.legend(handles, ['Other', 'Sedan'])\n",
        "ax.add_patch(\n",
        "    plt.Rectangle((11, 12), 7, 5,   # Alto\n",
        "        fill=True, alpha=0.1, color=\"red\"\n",
        "    )\n",
        ")\n",
        "ax.text(11, 17.1, \"$C$\", color=\"red\")\n",
        "plt.xlabel(\"Price\")\n",
        "plt.ylabel(\"Engine Power\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckVO5fRZQk7q"
      },
      "source": [
        "Suppose we propose a rule to classify cars based on a range of both attributes,\n",
        "$$\\mathscr{H}: (p_1 \\leq \\text{price} \\leq p2) \\ \\land (e_1 \\leq \\text{engine power} \\leq e_2)$$\n",
        "for suitable values of $p_1, \\ p_2, \\ e_1, \\ e_2$ (**parameters**). That is, we assume that C is a rectangle in the engine power-price space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmVFWOkPSROv"
      },
      "source": [
        "The inequality $\\mathscr{H}$ is the **hypothesis class** from which we belive $C$ is drawn, namely, the set of rectangles. The **learning algorihtm** then finds the **particular hypothesis** $h\\in \\mathscr{H}$, to approximate $C$ as closely as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_fwpFyITCve"
      },
      "source": [
        "Though we define the hypothesis class, the values of the **parameters** are not known; that is, though we choose $\\mathscr{H}$, we do not know which particular $h\\in \\mathscr{H}$ is equal, or closest, to $C$. But once we restrict our attention to this hypothesis class, learning the class reduces to the easier\n",
        "problem of finding the four parameters that define $h$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxvvBfznTT4a"
      },
      "source": [
        "The aim is to find $h\\in \\mathscr{H}$ that is as similar as possible to $C$. Let us say the hypothesis $h$ makes a **prediction** for an **instance** $x$ such that\n",
        "$$h(x) = \\begin{cases}1 \\ \\text{if $h$ classifies $x$ as a positive example}\\\\ 0 \\ \\text{if $h$ classifies $x$ as a negative example} \\end{cases}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Empirical error**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY7_UaYSTyhE"
      },
      "source": [
        "In real life we do not know $C(x)$, so we cannot evaluate how well $h(x)$ matches $C(x)$.\n",
        "What we have is the **training set** $X$, which is a small subset of the set of all possible empirical error x.\n",
        "\n",
        "The **empirical error** is the proportion of training instances where predictions of $h$ do not match the required values given in $X$. The error of hypothesis $h$ given the training set $X$ is\n",
        "$$E(h|X) = \\sum_{i=1}^N 1\\left(h(x^i) \\neq r^i\\right)$$\n",
        "where $1(a \\neq b)$ is 1 if a $a\\neq b$ and is 0 if $a = b$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkVpqFuZ7zOE"
      },
      "source": [
        "In our example, the hypothesis class $\\mathscr{H}$ is the set of all possible rectangles. Each quadruple $(p_1^h, p_2^h, e_1^h, e_2^h)$ defines one hypothesis, $h$, from $\\mathscr{H}$, and we need to choose the best one, or in other words, we need to find the values of these four parameters **given the training set**, to include all the positive examples and none of the negative examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Generalization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toGGbGHg9YWC"
      },
      "source": [
        "There are infinitely many such $h$ for which this is satisfied, namely, for which the error, $E$, is 0, but given a future example, different candidate hypotheses may make different predictions.\n",
        "\n",
        "This is the problem of **generalization**, that is, how well our\n",
        "hypothesis will **correctly classify future examples** that are not part of the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wShH-K6IFFCg"
      },
      "source": [
        "One possibility is to find the most **specific hypothesis**, $S$, that is the\n",
        "tightest rectangle that includes all the positive examples and none of the negative examples. Note that the actual class C may be larger than S but is most general never smaller.\n",
        "\n",
        "The most **general hypothesis**, $G$, is the largest rectangle we\n",
        "can draw that includes all the positive examples and none of the negative examples.\n",
        "\n",
        "Any $h \\in \\mathscr{H}$ between $S$ and $G$ is a valid hypothesis with no error, said to be **consistent** with the training set, and such $h$ make\n",
        "up the **version space**. Given another training set, $S$, $G$, version space, the parameters and thus the learned hypothesis, $h$, can be different."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "V3GRE1DUA6qi",
        "outputId": "d7483cc7-9853-4e2b-89b3-77a19d803a46"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ax.add_patch(\n",
        "    plt.Rectangle((11.4, 13.9), 3.7, 2.3, fill=False,  edgecolor=\"black\")\n",
        ")\n",
        "ax.text(15.2, 16.1, \"$S$\")\n",
        "ax.add_patch(\n",
        "    plt.Rectangle((9.9, 10.5), 8.1, 10.3, fill=False, edgecolor=\"black\")\n",
        ")\n",
        "ax.text(18.1, 10.5, \"$G$\")\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EVQaExpqi1_"
      },
      "source": [
        "### **Learning Multiple Classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnA5q1TUqmVi"
      },
      "source": [
        "In our example of learning a sedan car, we have positive examples belonging to the class sedan car and the negative examples belonging to all other cars. This is a **two-class problem**.\n",
        "\n",
        "In the general case, we have $K$ classes denoted as $C_l, \\  l= 1,\\ldots,K$, and an input instance belongs **to one and exactly one** of them.\n",
        "\n",
        "The training set is now of the form\n",
        "$$X =\\left\\{x^i, r^i\\right\\}^N_{i=1}$$\n",
        "where $r$ has $K$ dimensions and\n",
        "$$r_l^i = \\begin{cases} 1 \\quad \\text{if} \\ x^i\\in C_l\\\\ 0 \\quad \\ \\text{if} \\  x^i\\in C_j, \\ j\\neq l \\end{cases}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zqt5tH4ruRz"
      },
      "source": [
        "In machine learning for **classification**, we would like **to learn the boundary separating** the instances of one class from the instances of all other classes.\n",
        "\n",
        "Thus we view a **$K$-class classification problem** as $K$ two-class problems. The training examples belonging to $C_l$ are the positive instances\n",
        "of hypothesis $h_l$ and the examples of all other classes are the negative instances of $h_l$.\n",
        "\n",
        "Thus in a $K$-class problem, we have $K$ hypotheses\n",
        "to learn such that\n",
        "$$h_l(x^i) = \\begin{cases} 1 \\quad \\text{if} \\ x^i\\in C_l\\\\ 0 \\quad \\ \\text{if} \\  x^i\\in C_j, \\ j\\neq l \\end{cases}$$\n",
        "\n",
        "The **total empirical error** takes a sum over the predictions for all classes over all instances:\n",
        "$$E\\left(\\{h_l\\}_{l=1}^K \\ | \\ X \\right) = \\sum_{i=1}^N \\sum_{l=1}^K 1(h_l(x^i) \\neq r_l^i)$$\n",
        "\n",
        "For a given instance $x$, ideally only one of $h_l(x), l = 1,\\ldots, K$ is 1 and we canchoose a class. But when no, or two or more, $h_l(x)$ is 1, we cannot choose a class, and this is the case of doubt and the classifier **rejects** such cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEm7edpIEuPJ"
      },
      "source": [
        "### **Vapnik-Chervonenkis (VC) Dimension**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyJq1YSWEy2g"
      },
      "source": [
        "We **assume** that $\\mathscr{H}$ includes $C$; that is, **there exists** $h \\in \\mathscr{H}$, such that $E(h|X)$ is 0. Given a hypothesis class $\\mathscr{H}$, it may be the case that **we cannot learn C**; that is, there exists no $h \\in \\mathscr{H}$ for which the error is 0. Thus, in any application, we need to make sure that $\\mathscr{H}$ is flexible enough, or has enough **capacity**, to learn C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on4BrxyOHEfw"
      },
      "source": [
        "Let us say we have a dataset containing $N$ points. These $N$ points can be labeled in $2^N$ ways as positive and negative. Therefore, $2^N$ different **learning problems** can be defined by $N$ data points.\n",
        "\n",
        "If for **any** of these problems, we can find a hypothesis $h\\in \\mathscr{H}$ that separates the positive examples from the negative, then we say $\\mathscr{H}$ **shatters** N points. That is, any\n",
        "learning problem definable by $N$ examples **can be learned** with no error by a hypothesis drawn from  $\\mathscr{H}$.\n",
        "\n",
        "The maximum number of points that can be shattered by  $\\mathscr{H}$ is called the **Vapnik-Chervonenkis (VC) dimension** of  $\\mathscr{H}$, is denoted as $VC(\\mathscr{H})$, and measures the **capacity** of $\\mathscr{H}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nv9zBplLHwt"
      },
      "source": [
        "#### *Example*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbVv222nLIvW"
      },
      "source": [
        "Then $VC(\\mathscr{H})$, when $\\mathscr{H}$ is the hypothesis class of axis-aligned rectangles in two dimensions, is four. In calculating the\n",
        "$VC$ dimension, it is enough that we find four points that can be shattered;\n",
        "it is not necessary that we be able to shatter any four points in two dimensions. For example, four points placed on a line cannot be shattered\n",
        "by rectangles. However, we cannot place five points in two dimensions\n",
        "anywhere such that a rectangle can separate the positive and negative\n",
        "examples for all possible labelings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rc-C_5WLnCl"
      },
      "source": [
        "VC dimension may seem pessimistic. It tells us that using a rectangle\n",
        "as our hypothesis class, we can learn only datasets containing four points\n",
        "and not more. A learning algorithm that can learn datasets of four points\n",
        "is not very useful.\n",
        "\n",
        "However, this is because the **VC dimension** is **independent**\n",
        "of the **probability distribution** from which instances are drawn. In real life, the world is smoothly changing, instances close by most of the time have the same labels, and we need not worry about all possible labelings. There are a lot of datasets containing many more data points than four that are learnable by our hypothesis class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd92CqPTMF3A"
      },
      "source": [
        "VC dimension of some popular classifiers:\n",
        "\n",
        "- **Linear classifiers** in $\\mathbb{R}^d$,\n",
        "$$ \\mathscr{F} = \\left\\{f: f(x) = sign(w^T x), \\ w\\in \\mathbb{R}^d\\right\\}$$\n",
        "is $d$.\n",
        "- **Affine classifiers**\n",
        "$$ \\mathscr{F}^{'} = \\left\\{f: f(x) = sign(w^T x+w_0), \\ w\\in \\mathbb{R}^d, \\ w_0\\in \\mathbb{R}\\right\\}$$\n",
        "is $d+1$\n",
        "- The **$k$-Nearest neighbors algorithm** using $k=1$ is **infinite**\n",
        "- **Support Vector Machines (SVM)** with radial basis kernel have **infinite** VC dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<style>\n",
        ".bubble {\n",
        "  max-width: 70%;\n",
        "  width: fit-content;\n",
        "  word-wrap: break-word; \n",
        "  padding: 10px;\n",
        "  border-radius: 10px;\n",
        "  color: #ffffff;\n",
        "}\n",
        ".left {\n",
        "  background-color: #333333;\n",
        "}\n",
        ".right {\n",
        "  background-color: #4285F4;\n",
        "  text-align: right;\n",
        "  margin-left: auto;\n",
        "}\n",
        "</style>\n",
        "\n",
        "<div class=\"bubble right\">\n",
        "Dame más ejemplos\n",
        "\n",
        ".\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La **dimensión VC** (Vapnik-Chervonenkis) es una medida que indica la capacidad de un modelo de aprendizaje o una familia de funciones para **clasificar conjuntos de datos de forma perfecta**. Es el tamaño máximo de un conjunto de puntos que puede ser **completamente \"shattereado\"** por la familia de funciones (es decir, clasificado de todas las maneras posibles). A continuación, te doy ejemplos de la dimensión VC para diferentes familias de clasificadores:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Rectas en el plano ($\\mathbb{R}^2$)**\n",
        "- **Modelo**: Clasificadores lineales en el plano.\n",
        "- **Dimensión VC**: $3$.\n",
        "  - Tres puntos en $\\mathbb{R}^2$ pueden ser separados en cualquier configuración (e.g., etiquetas como $\\{+1, -1\\}$) con una línea recta.\n",
        "  - Sin embargo, no se puede garantizar lo mismo para cuatro puntos en disposición específica (como vértices de un cuadrado)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. **Hiperplanos en $\\mathbb{R}^n$**\n",
        "- **Modelo**: Clasificadores lineales en espacios de mayor dimensión.\n",
        "- **Dimensión VC**: $n+1$.\n",
        "  - Un hiperplano puede separar hasta $n+1$ puntos en cualquier configuración, pero no $n+2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Parábolas en el plano ($\\mathbb{R}^2$)**\n",
        "- **Modelo**: Conjunto de parábolas en 2D.\n",
        "- **Dimensión VC**: $5$.\n",
        "  - Hasta 5 puntos en el plano pueden ser clasificados de todas las maneras posibles por parábolas.\n",
        "  - No se puede garantizar lo mismo para 6 puntos en configuraciones específicas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. **Círculos en el plano ($\\mathbb{R}^2$)**\n",
        "- **Modelo**: Conjuntos definidos por círculos.\n",
        "- **Dimensión VC**: $3$.\n",
        "  - Tres puntos en el plano pueden ser separados en cualquier configuración por un círculo (dentro o fuera del círculo).\n",
        "  - Cuatro puntos no pueden ser siempre separados en todas las combinaciones posibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. **Intervalos en la recta ($\\mathbb{R}$)**\n",
        "- **Modelo**: Clasificadores definidos por intervalos $[a, b]$.\n",
        "- **Dimensión VC**: $2$.\n",
        "  - Se pueden clasificar hasta dos puntos en la línea real en todas las configuraciones posibles con un intervalo.\n",
        "  - Tres puntos no pueden ser clasificados en todas las configuraciones posibles.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. **Conjuntos finitos de funciones constantes**\n",
        "- **Modelo**: Clasificadores que siempre predicen una constante (e.g., $f(x) = c$).\n",
        "- **Dimensión VC**: $1$.\n",
        "  - Solo un punto puede ser clasificado correctamente de todas las maneras posibles (si $f(x) = c$, no puede \"adaptarse\" a configuraciones más complejas)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. **Redes neuronales con una capa oculta y activaciones lineales por partes**\n",
        "- **Modelo**: Red neuronal con $W$ pesos ajustables.\n",
        "- **Dimensión VC**: Proporcional a $W$ (generalmente se aproxima como $W + 1$).\n",
        "  - Por ejemplo, una red con 10 pesos ajustables tendrá una dimensión VC de aproximadamente $11$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "8. **Máquinas de soporte vectorial (SVM) con kernel lineal**\n",
        "- **Modelo**: SVM en espacios de características lineales.\n",
        "- **Dimensión VC**: Depende de las dimensiones del espacio de entrada.\n",
        "  - Por ejemplo, si el espacio tiene $d$ dimensiones, la VC-dimensión está acotada por $d+1$.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "9. **Conjuntos de funciones polinomiales de grado $d$ en $\\mathbb{R}$**\n",
        "- **Modelo**: Polinomios de grado $d$.\n",
        "- **Dimensión VC**: $d+1$.\n",
        "  - Por ejemplo, un polinomio cuadrático ($d=2$) tiene dimensión VC igual a $3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<style>\n",
        ".bubble {\n",
        "  max-width: 70%;\n",
        "  width: fit-content;\n",
        "  word-wrap: break-word; \n",
        "  padding: 10px;\n",
        "  border-radius: 10px;\n",
        "  color: #ffffff;\n",
        "}\n",
        ".left {\n",
        "  background-color: #333333;\n",
        "}\n",
        ".right {\n",
        "  background-color: #4285F4;\n",
        "  text-align: right;\n",
        "  margin-left: auto;\n",
        "}\n",
        "</style>\n",
        "\n",
        "<div class=\"bubble right\">\n",
        "¿Cómo encuentro la dimensión VC de algo?\n",
        "\n",
        ".\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para encontrar la **dimensión VC** de una familia de clasificadores o funciones, debes determinar el **número máximo de puntos** que pueden ser **shattereados** por esa familia. Un conjunto de puntos se dice que es **shattereado** si la familia de funciones puede clasificar esos puntos en **todas las configuraciones posibles de etiquetas binarias** ($+1$ y $-1$). El proceso se realiza en los siguientes pasos:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**1. Define la familia de funciones o clasificadores**\n",
        "Primero, debes tener claro cuál es la familia de clasificadores que estás analizando. Ejemplos:\n",
        "- Líneas rectas (clasificadores lineales) en $\\mathbb{R}^2$.\n",
        "- Hiperplanos en $\\mathbb{R}^n$.\n",
        "- Círculos en el plano.\n",
        "- Polinomios de grado $d$.\n",
        "- Redes neuronales con activaciones específicas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**2. Encuentra el conjunto de puntos máximo que puede ser shattereado**\n",
        "Este es el núcleo del problema. Sigue los siguientes subpasos:\n",
        "\n",
        "**a) Escoge un conjunto de puntos arbitrarios**\n",
        "Supón que tomas $n$ puntos en tu espacio de entrada. Estos puntos deben ser elegidos de forma general (sin degeneraciones o simetrías específicas que podrían facilitar o dificultar la clasificación).\n",
        "\n",
        "**b) Determina si puedes generar todas las configuraciones de etiquetas posibles**\n",
        "Para $n$ puntos, hay $2^n$ combinaciones posibles de etiquetas ($+1, -1$). Verifica si la familia de funciones puede clasificar los puntos para **cada configuración de etiquetas**.\n",
        "\n",
        "- **Si es posible para todas las configuraciones**, entonces el conjunto de puntos es **shattereado** por la familia de funciones.\n",
        "- Si no es posible para al menos una configuración, entonces $n$ **no puede ser la dimensión VC**.\n",
        "\n",
        "**c) Incrementa $n$ y repite**\n",
        "- Aumenta el número de puntos $n$ y vuelve a verificar si puedes shatterear todas las configuraciones.\n",
        "- La **dimensión VC** será el valor máximo de $n$ tal que los puntos pueden ser shattereados. Para $n+1$ puntos, ya no será posible shatterear todas las configuraciones.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**3. Ejemplo: Líneas rectas en $\\mathbb{R}^2$**\n",
        "Paso 1: Familia de clasificadores\n",
        "- Funciones lineales de la forma $f(x, y) = ax + by + c$ que dividen el plano en dos regiones.\n",
        "\n",
        "Paso 2: Determinar la dimensión VC\n",
        "- **Caso $n = 1$:** Un punto puede ser clasificado como $+1$ o $-1$ sin problemas.\n",
        "- **Caso $n = 2$:** Dos puntos pueden ser clasificados de cualquier forma (uno como $+1$, el otro como $-1$, o ambos iguales), ya que siempre puedes trazar una línea entre ellos.\n",
        "- **Caso $n = 3$:** Tres puntos no colineales pueden ser separados en cualquier configuración. Ejemplo:\n",
        "  - $\\{+1, -1, +1\\}$: Separa con una línea que pase entre el segundo y tercer punto.\n",
        "- **Caso $n = 4$:** Si los cuatro puntos forman un cuadrado, no siempre es posible separar todas las configuraciones (por ejemplo, $\\{+1, -1, +1, -1\\}$).\n",
        "\n",
        "Por lo tanto, la **dimensión VC** de las líneas rectas en $\\mathbb{R}^2$ es $3$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**4. Observaciones importantes**\n",
        "- **Teoría combinatoria:** Si tienes intuición en combinatoria, puedes razonar sobre cuántas configuraciones posibles de etiquetas pueden cubrirse con las funciones dadas.\n",
        "- **Pruebas formales:** Para casos complejos (e.g., redes neuronales), se usan herramientas matemáticas avanzadas, como conteos combinatorios y teoría de la probabilidad.\n",
        "- **Propiedades geométricas:** Algunas familias, como círculos o parábolas, requieren analizar propiedades geométricas del espacio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<style>\n",
        ".bubble {\n",
        "  max-width: 70%;\n",
        "  width: fit-content;\n",
        "  word-wrap: break-word; \n",
        "  padding: 10px;\n",
        "  border-radius: 10px;\n",
        "  color: #ffffff;\n",
        "}\n",
        ".left {\n",
        "  background-color: #333333;\n",
        "}\n",
        ".right {\n",
        "  background-color: #4285F4;\n",
        "  text-align: right;\n",
        "  margin-left: auto;\n",
        "}\n",
        "</style>\n",
        "\n",
        "<div class=\"bubble right\">\n",
        "no se consideran los casos colineales?\n",
        "\n",
        ".\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "¡Muy buena pregunta! En el cálculo de la **dimensión VC**, **los puntos deben ser escogidos de manera \"general\"** para garantizar que no haya una configuración especial (como colinealidad o simetrías específicas) que reduzca artificialmente la capacidad del clasificador. Esto significa que **los casos colineales no se consideran como un obstáculo** al determinar la dimensión VC porque no representan la situación más general del modelo.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Por qué no se consideran los puntos colineales:**\n",
        "1. **La dimensión VC mide la capacidad máxima del modelo:**\n",
        "   La dimensión VC es el **número máximo de puntos** que pueden ser **shattereados en cualquier configuración**. Si los puntos son colineales, introduces restricciones geométricas que dificultan la separación, pero esto no refleja la capacidad completa del clasificador en situaciones generales.\n",
        "\n",
        "2. **Se consideran puntos en posición general:**\n",
        "   Para evitar casos degenerados (como colinealidad en clasificadores lineales o coplanaridad en clasificadores no lineales), los puntos deben ser tomados en **posición general**. Esto significa que:\n",
        "   - En $\\mathbb{R}^2$, los puntos no deben ser colineales.\n",
        "   - En $\\mathbb{R}^3$, los puntos no deben ser coplanarios.\n",
        "   - En general, los puntos no deben satisfacer restricciones que limiten la capacidad del clasificador.\n",
        "\n",
        "3. **Restricciones degeneradas no reflejan la realidad:**\n",
        "   Los puntos colineales restringen las posibles configuraciones que el clasificador puede manejar. Esto no refleja el caso general donde los datos son distribuidos de forma más libre. Por ejemplo:\n",
        "   - Si estás evaluando líneas rectas en $\\mathbb{R}^2$, los puntos colineales siempre se podrán separar perfectamente porque caen en una sola dimensión, lo cual subestima la capacidad real del clasificador en el plano.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Ejemplo: Líneas rectas en $\\mathbb{R}^2$**\n",
        "1. **Caso general (no colineales):**\n",
        "   Tres puntos no colineales en $\\mathbb{R}^2$ **pueden ser clasificados de todas las maneras posibles** ($2^3 = 8$ combinaciones), ya que puedes trazar líneas para separar cualquier configuración.\n",
        "\n",
        "2. **Caso degenerado (colineales):**\n",
        "   Tres puntos colineales **no pueden ser clasificados de todas las maneras posibles**. Por ejemplo:\n",
        "   - La configuración $\\{+1, -1, +1\\}$ no es separable con una línea recta porque están alineados.\n",
        "\n",
        "En este caso, la colinealidad restringe las configuraciones posibles, pero no se toma en cuenta al calcular la dimensión VC porque **se buscan configuraciones generales y no degeneradas**.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Regla clave:**\n",
        "**Para calcular la dimensión VC, los puntos deben ser colocados en configuraciones que maximicen la capacidad del clasificador.** Esto implica evitar restricciones geométricas especiales como colinealidad o coplanaridad, ya que estas no representan el comportamiento general del modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J83uvB7VF1lN"
      },
      "source": [
        "### **Noise**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHx9_zXSF2-4"
      },
      "source": [
        "**Noise** is any unwanted anomaly in the data and due to noise, the class\n",
        "may be more difficult to learn and zero error may be infeasible with a simple hypothesis class.\n",
        "\n",
        "There are several interpretations of noise:\n",
        "- There may be **imprecision in recording the input attributes**, which may\n",
        "shift the data points in the input space.\n",
        "- There may be **errors in labeling** the data points, which may relabel positive instances as negative and vice versa. This is sometimes called\n",
        "**teacher noise**.\n",
        "- There may be **additional attributes**, which we have not taken into account,\n",
        "that affect the label of an instance. Such attributes may be hidden or latent in that they may be **unobservable**. The effect of these neglected attributes is thus modeled as a random component and is included in noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fzsOTuzdNGk"
      },
      "source": [
        "### **Model Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_SYizpKdPBL"
      },
      "source": [
        "Each **hypothesis class** has a certain **capacity** and can **learn** only certain functions. The class of functions that can be learned can be extended by using a hypothesis class with larger capacity, containing more complex hypotheses. For example, the hypothesis class that is a union of two rectangles has higher capacity, but its hypotheses are more complex.\n",
        "\n",
        "Thus learning is not possible without **inductive bias**, and now the question is how to choose the right bias. This is called **model selection**, which is choosing between possible $\\mathscr{h}$.\n",
        "\n",
        "In answering this question, we should\n",
        "remember that the **aim** of machine learning is rarely to replicate the training data but the **prediction for new cases**.\n",
        "\n",
        "That is we would like to be able to generate the right output for an input instance outside the training set, one for which the correct output is not given in the training set. How well a model trained on the training set predicts the right output for new generalization instances is called **generalization**.\n",
        "\n",
        "For best generalization, we should match the complexity of the hypothesis\n",
        "class $\\mathscr{h}$ with the complexity of the function underlying the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nu79MgNfbKI"
      },
      "source": [
        "- If $\\mathcal{H}$ is less complex than the function, we have **underfitting**. In\n",
        "such a case, as we increase the complexity, the training error decreases.\n",
        "\n",
        "- If we have $\\mathcal{H}$ that is too complex, the data is not enough to constrain\n",
        "it and we may end up with a bad hypothesis, $h$. This is called **overfitting**. In such a case, having more training data helps but only up to a certain point. Given a training\n",
        "set and hypothesis set, we can find $h\\in \\mathcal{H}$ that has the minimum training error but if $\\mathcal{H}$ is not chosen well, no matter which $h$ we pick, we will not have\n",
        "good generalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PzjlZKCGoyx"
      },
      "source": [
        "In all **learning algorithms** that are trained from example data,\n",
        "there is a trade-off between three factors:\n",
        "- The **complexity of the hypothesis** we fit to data, namely, the **capacity**\n",
        "of the hypothesis class.\n",
        "- The amount of **training data**.\n",
        "- The **generalization error** on new examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66q0u4xqG3Oj"
      },
      "source": [
        "As the amount of training data increases, the generalization error decreases.\n",
        "\n",
        "As the complexity of the model class $\\mathscr{H}$ increases, the generalization error decreases first and then starts to increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdri17GSHRbC"
      },
      "source": [
        "We can **measure** the **generalization ability** of a hypothesis, namely, the\n",
        "**quality** of its inductive bias, if we have access to data outside the training set.\n",
        "\n",
        " We simulate this by dividing the training set we have into two parts.\n",
        "We use one part for **training** (i.e., to fit a hypothesis), and the remaining part is called the **validation set** and is used to test the generalization ability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adOjU3A-HtfL"
      },
      "source": [
        "That is, given a set of possible hypothesis classes $\\mathscr{H}_i$, for each\n",
        "we fit the best $h_i \\in \\mathscr{H}_i$ on the training set. Then, assuming large enough\n",
        "training and validation sets, the hypothesis that is the most accurate on\n",
        "the validation set is the best one (the one that has the best inductive bias). This process is called **cross-validation**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ8UTTzcIHMp"
      },
      "source": [
        "Note that if we need **to report the error** to give an idea about the expected error of our best model, we should not use the validation error.\n",
        "We have used the **validation set to choose the best model**, and it has effectively become a part of the training set. We need a third set, a **test set**, containing examples not used in training or validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5KXO0g_oCgc"
      },
      "source": [
        "### **Learning theory**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcSlVXDkKY7M"
      },
      "source": [
        "**Machine learning** works from data. In **supervised learning**, the machine is given both input data and output labels, from which it produces a model that can predict the label for any input. In **unsupervised learning**, the machine is only given a set of input data from which it should extract knowledge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmAOLBWF8BzJ"
      },
      "source": [
        "### **Input data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfP4bL-xoU8p"
      },
      "source": [
        "We denote an input by $x$  and assume that all inputs are taken from **a set of possible inputs**, known as the **input space** $\\mathcal{X}$\n",
        "\n",
        "In this course, we assume that the inputs are real $d$-dimensional vectors, i.e.,\n",
        "$$x\\in \\mathcal{X} \\subseteq \\mathbb{R}^d$$\n",
        "The word **features** will refer to the components x\n",
        "$$x_j \\in \\mathbb{R}^d, \\quad j=1,\\ldots,d$$\n",
        "of the input vectors\n",
        "$$x=[x_1,\\ldots,x_d]^T$$\n",
        "\n",
        "We will often consider sets of input vectors indexed by $i$ as $x_i$ or $x^i$. In this case, the $j$ th component of $x_i$ is denoted $x_{ij}$.\n",
        "\n",
        "We will also consider inputs as **random vectors** $X$. In this context, $x$ refers to a realization of $X$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcz_fIfw8BS8"
      },
      "source": [
        "### **Output labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buy0XOg68G0q"
      },
      "source": [
        "We denote a **label** by $y$ and assume that all labels for a given problem are taken from a set of possible labels $\\mathcal{Y}$.\n",
        "\n",
        "We restain ourselves to labels  $y$ that are either taken from a discrete set of integers, i.e., \n",
        "$\\mathcal{Y}\\subset \\mathbb{Z}$, due we are dealing with a **classification problem**. (In the case of a regression problem $\\mathcal{Y}\\subseteq \\mathbb{R}$).\n",
        "\n",
        "Most of the time, we will also consider labels as random variables $Y$  taking values in $\\mathcal{Y}$ In this context, $y$ refers to a realization of $Y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> En este contexto, \"la realización de\" significa el valor específico que toma una variable aleatoria en un caso particular o experimento dado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZeGvYpOcSX0"
      },
      "source": [
        "### **Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_1T_ocgcVOt"
      },
      "source": [
        "**Machine learning** is concerned with obtaining a **mapping** from the input space $\\mathcal{X}$  to the space of labels $\\mathcal{Y}$ from data in the case where the desired mapping cannot be explicited as a simple algorithm.\n",
        "\n",
        "If the available data contains only examples from $\\mathcal{X}$ , then this is **unsupervised learning**.\n",
        "\n",
        "If for each datum from $\\mathcal{X}$  the corresponding label in $\\mathcal{Y}$  is also given, then this is **supervised learning**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **\"mapping\"** se refiere a una **función** o una relación que asigna elementos de un conjunto a elementos de otro. Es una manera formal de describir cómo un modelo o algoritmo aprende una relación entre los **datos de entrada** y sus correspondientes **salidas**.\n",
        " \n",
        "> Definición en el contexto de machine learning:\n",
        "> Un **mapping** es una función $f: \\mathcal{X} \\to \\mathcal{Y}$, donde:\n",
        "> - $\\mathcal{X}$ es el **espacio de entrada** (también llamado dominio, por ejemplo, características o variables independientes).\n",
        "> - $\\mathcal{Y}$ es el **espacio de salida** (también llamado codominio, por ejemplo, etiquetas o variables dependientes).\n",
        "> - $f$ es la función que el modelo intenta aprender para predecir $y$ dados $x$, es decir, $f(x) = y$.\n",
        "\n",
        "> **Ejemplo:**\n",
        "> - Si estás trabajando en un problema de clasificación, el mapping sería una función que asigna un conjunto de características ($x$) a una clase específica ($y$).\n",
        "> - Si estás en un problema de regresión, el mapping asigna $x$ a un valor numérico $y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- > Definición de Machine Learning (ML): -->\n",
        "\n",
        "> **Machine Learning** es una rama de la inteligencia artificial que se centra en el desarrollo de **algoritmos y modelos matemáticos** que permiten a las computadoras aprender patrones a partir de **datos** sin ser programadas explícitamente para realizar tareas específicas.\n",
        "\n",
        "> De manera formal:\n",
        "> **Machine Learning** es el estudio de algoritmos que permiten construir un **mapping** $f: \\mathcal{X} \\to \\mathcal{Y}$, tal que el modelo pueda hacer predicciones o tomar decisiones basadas en datos de entrada $\\mathcal{X}$, optimizando alguna métrica de rendimiento y generalizando a nuevos datos.\n",
        "\n",
        "> Elementos principales:\n",
        "> 1. **Datos ($\\mathcal{X}, \\mathcal{Y}$)**: Observaciones que consisten en entradas ($x$) y salidas ($y$).\n",
        "> 2. **Modelo o Mapping ($f$)**: Relación que el algoritmo aprende entre entradas y salidas.\n",
        "> 3. **Entrenamiento**: Proceso de ajustar $f$ con los datos de entrenamiento para minimizar el error.\n",
        "> 4. **Generalización**: Habilidad del modelo para predecir correctamente en datos no vistos (de prueba)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTi-6sml9K-3"
      },
      "source": [
        "### **Predictive models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG_Y33ZLKq4H"
      },
      "source": [
        "In a **machine learning problem** characterized by a given input space and a given label space, a **predictive model** is a function that assigns a label to every possible input; and we call **predictions** the outputs of such a function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy7PyS7G9PeM"
      },
      "source": [
        "Given an input space $\\mathcal{X}$ and a label space $\\mathcal{Y}$, a **predictive model** is a function\n",
        "$$f: \\ \\mathcal{X} \\rightarrow \\mathcal{Y}$$\n",
        "that maps any input vector $x$ to a label $f(x)$, called a **prediction**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MILiHsK2K_Tp"
      },
      "source": [
        "Thus, **learning** can be formulated as the search for a model in the space of all such functions, denoted $\\mathcal{Y}^{\\mathcal{X}}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JISM5QyLBOX"
      },
      "source": [
        "However, this approach is usually not as directly implemented by learning algorithms for two major reasons:\n",
        "-  This approach might be **algorithmically intractable**, since it is very difficult for an algorithm to implement any function from the input space to the label space.\n",
        "- Even if we could implement all these functions, we would not be able to determine which one is the best one and the algorithm would be prone to **overfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahO3PrjDK0PC"
      },
      "source": [
        "Instead of searching for a model in the set of all such function $\\mathcal{Y}^{\\mathcal{X}}$. most **learning algorithms** consider a restricted model space\n",
        "$$\\mathcal{F} \\subset \\mathcal{Y}^{\\mathcal{X}}$$\n",
        "also called a **function class**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ewJMEW9VtV8"
      },
      "source": [
        "A popular example of such a function class is the set of all **linear classifiers** for two class problem. With input space $\\mathcal{X}\\subseteq \\mathbb{R}^d$ and label space and label space $\\mathcal{Y} = \\{-1,1\\}$, this can be represented as\n",
        "$$\\mathcal{F} = \\{ f\\in \\mathcal{Y}^{\\mathcal{X}}: \\quad f(x) = \\text{sign}(w^Tx + w_0), \\ w\\in \\mathbb{R}^d, \\ w_0\\in \\mathbb{R}\\}$$\n",
        "Here, the parameters of the model that have to be learned from data are the components of the parameter vector $w$ and the bias $w_0$. This means that any pair $(w, w_0)$ uniquely defines a model $f$ in the function class $\\mathcal{F}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7WU5wK5--H2"
      },
      "source": [
        "In a **supervised learning problem** with input space $\\mathcal{X}$ and label space  $\\mathcal{Y}$, a **learning algorithm** $\\mathcal{A}$ is a mapping of the form\n",
        "$$A: \\ \\left(\\mathcal{F},\\ \\{(x_i,y_i)\\}^N_{i=1}\\right)\\rightarrow f\\in \\mathcal{F}$$\n",
        "where $\\mathcal{F}$ is a set of possible models, $$\\{(x_i,\\ y_i)\\}^N_{i=1} \\in (\\mathcal{X}, \\mathcal{Y})^N$$\n",
        " is a training set and $f$ is the returned predictive model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbyP27O1LgWH"
      },
      "source": [
        "In machine learning, we often encounter **parameterized function classes** for which the class of functions itself is defined up to the value of some parameters. A typical example is the class of polynomials parametrized by the degree of the polynomials.\n",
        "\n",
        "In order to distinguish between the **parameters of the model** and the **parameters of the model class**, we call the latter **hyperparameters**.\n",
        "\n",
        "The distinction between parameters and hyperparameters is of primary importance in order to understand the overall learning procedure. Indeed, while the values of the parameters are automatically determined by the learning algorithm, the hyperparameters must be tuned by the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNh-Okcn_2li"
      },
      "source": [
        "Some learning algorithms have one or more parameters that have to **be tuned by the user**. To differentiate these from the model parameters that **are learned** when applying the algorithm, we call the parameters of an algorithm its **hyperparameters**. In this case, the mapping takes the form\n",
        "$$A: \\ \\left(\\mathcal{F},\\ \\{(x_i,y_i)\\}^N_{i=1},\\ \\gamma\\right)\\rightarrow f\\in \\mathcal{F}$$\n",
        "for a generic (and possibly multidimensional) hyperparameter $\\gamma$.\n",
        ".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd6a2_knZIcx"
      },
      "source": [
        "### **The risk and the loss function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LVo_KkQZKXO"
      },
      "source": [
        "In supervised learning, a **loss function** $$\\mathcal{l}: \\mathcal{Y}\\times \\mathcal{Y}\\rightarrow \\mathbb{R}^{+}$$\n",
        "computes a **pointwise measure** $\\mathcal{l}(y,\\hat{y})$ of the error between a label $y$  and its estimate $\\hat{y}$.\n",
        "\n",
        "For all $(y,\\hat{y})\\in \\mathcal{Y}^2$, a loss function satisfies\n",
        "$$\\mathcal{l}(y,\\hat{y})\\geq 0$$\n",
        "$$\\hat{y}=y \\quad \\Rightarrow  \\quad l(y, \\hat{y})=0$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OusLCQizWJ2A"
      },
      "source": [
        "The **risk** of a learning machine or model is the amount of **prediction error** that can be **expected** when using that model. The main goal in supervised learning is to **minimize this risk** in order to obtain the most accurate model.\n",
        "\n",
        "In the sentence above, the \"amount of error\" is measured via a loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS2mX2noJqXU"
      },
      "source": [
        "Given a loss function $\\mathcal{l}$, the **risk** of a model $f$ is defined as the expectation of the loss function applied to the output of the model:\n",
        "$$R(f)=E_{X,Y}[\\mathcal{l}(Y, f(X))]$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGggPD-5WcXr"
      },
      "source": [
        "The **risk** is not a quantity that can be computed exactly, since it measures the quality of predictions of unknown phenomena, and in practice must be estimated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUiDib3RWsOh"
      },
      "source": [
        "### **Estimating the risk with a test sample**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JowIzBbGW3IV"
      },
      "source": [
        "The most simple estimate of the risk is the **test error**.  It is the average loss computed on an **independent and identically** distributed data sample, called the **test sample**.\n",
        "\n",
        "If the test sample is not independent of the training sample, the test error cannot be considered as an estimate of the risk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxDTBubKWvZt"
      },
      "source": [
        "The **risk** is defined as the expectation of the loss function and thus cannot be computed without knowledge of the **true data distribution**.\n",
        "\n",
        "The **test error** is a simple estimate of the risk that can be computed from data. Assume that we have access to both a training sample\n",
        "$$D={(X_i,Y_i)}^N_{i=1}$$\n",
        "and a test sample\n",
        "$$D_{test}={(X_i^{'},Y_i^{'})}^{N_t}_{i=1}$$\n",
        "of $N$ and $N_t$ independent and identically distributed copies of $(X,Y)$.\n",
        "\n",
        "Note that this also implies the independence of $D$\n",
        " and $D_{test}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phtQhfc3X7Cl"
      },
      "source": [
        "The procedure is as follows: we train a model $f$  on the training sample and then **estimate its risk** from the test sample by computing the test error\n",
        "$$R_{test}(f)=\\frac{1}{N_t}\\sum_{i=1} \\mathcal{l}\\left(Y_i^{'}, \\ f(X_i^{'})\\right)$$\n",
        "The **law of large numbers** tells us that this estimate converges as $N_t$ tends towards infinity to the expectation of the loss function, i.e., to the risk of $f$.\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0qua1xdqOT1"
      },
      "source": [
        "### **Model selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE9-3erTqU_X"
      },
      "source": [
        "Given a function class $\\mathcal{F}_{\\rho}$ **parametrized** by $\\rho$ and a learning algorithm\n",
        "$$A: \\ \\left(\\mathcal{F}_{\\rho},\\ \\{(x_i,y_i), \\}^N_{i=1}, \\ \\gamma\\right)\\rightarrow f\\in \\mathcal{F}_{\\rho}$$\n",
        "parametrized by $\\gamma$, **model selection** amounts to finding the values of the hyperparameters $\\rho$ and $\\gamma$ that **minimize the risk** of the resulting model $f$.\n",
        "\n",
        "This task is intrinsically impossible since the risk cannot be computed exactly without access to the true data distribution, assumed to be unknown in supervised learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px2qB79fteoY"
      },
      "source": [
        "### **Estimation versus approximation error**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NasMPZmpuHdp"
      },
      "source": [
        "The **estimation erro**r is the error implied by the fact that the algorithm works with a **finite training set** that only partially reflects the true distribution of the data. By considering that the training set is obtained by randomly sampling the true distribution, this also incurs a certain variability in the resulting model.\n",
        "\n",
        "The **approximation error** is the error implied by the **choice of function class** and is defined as the difference in risk obtained by the best model within the function class and the optimal model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cagFGmkruRgY"
      },
      "source": [
        "Given a supervised learning problem with a fixed distribution of the random pair of inputs $X\\in \\mathcal{X}$ and labels $Y\\in \\mathcal{Y}$, one can define the **optimal target model** $t$ as the one with minimal risk\n",
        "$$R^{∗}=R(t)=\\inf_{f:\\mathcal{X}\\rightarrow \\mathcal{Y}} R(f)$$\n",
        "In this definition, the minimum is considered over all possible functions from the input space $\\mathcal{X}$  to the label space $\\mathcal{Y}$\n",
        "\n",
        "Another important model when considering algorithms working with a restricted function class $\\mathcal{F}$, is the **best model within the class**:\n",
        "$$f^{∗}=\\arg\\min_{f∈\\mathcal{F}} R(f)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdmUosKEvBnr"
      },
      "source": [
        "With these definitions, the excess in error of a model $f$\n",
        " can be decomposed as\n",
        "$$R(f)−R^{∗}=[R(f)−R(f^{∗})]+[R(f^{*})-R^{*}]$$\n",
        "where the **estimation error** (first term) reflects the inability of the learning algorithm to find the best model $f^{*}$ in the class $\\mathcal{F}$, while the **approximation error** (second term) is induced by the limited capacity of the chosen function class $\\mathcal{F}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA-iIFh2xEhV"
      },
      "source": [
        "### **Regularization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOc3rnPXxF5B"
      },
      "source": [
        "**Regularization** is a versatile approach to the problem of **overfitting**, which can be seen as a **modification of empirical risk minimization** with control of the **model complexity**.\n",
        "\n",
        "In this approach, we minimize a trade-off between the training error and a regularization term which penalizes complex models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_3kfPDAyPFt"
      },
      "source": [
        "**Regularized learning** in a function class $\\mathcal{F}$ can be posed as the **functional optimization problem**\n",
        "$$min_{f\\in \\mathcal{F}} R_{emp}(f)+\\lambda \\Omega(f)$$\n",
        "where $R_{emp}(f)$ is the empirical risk of $f$\n",
        "$$R_{emp}(f)=\\sum_{i=1}^N \\mathcal{l}(y_i,f(x_i))$$\n",
        "using a loss function $\\mathcal{l}$, $\\Omega:\\mathcal{F}\\rightarrow \\mathbb{R}^+$ is a **regularizer** which penalizes too complex functions $f$, and $\\lambda>0$  is a hyperparameter tuning the trade-off between the fit to the training data and the regularization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8-xk6kkbmnf"
      },
      "source": [
        "### **References**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2XJ__9lbqFx"
      },
      "source": [
        "- Alpaydin, E. (2010) *Introduction to Machine Learning**, 2nd ed., The MIT Press.\n",
        "\n",
        "- Lauer, F. (2014) [*An Interactive Journey into Machine Learning*](https://mlweb.loria.fr/book/en/machinelearning.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
