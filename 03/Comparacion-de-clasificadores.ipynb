{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"position: relative; text-align: center; padding: 30px;\">\n",
    "  <h1><strong>Comparasión de Clasificadores</strong></h1>\n",
    "  <h3><strong>Walter y Heri</strong></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** El objetivo de esta actividad es que cada equipo cree una función que permita manejar diferentes formas de representación de clasificaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instrucciones:**\n",
    "- Construye una clase en Python que reciba una clasificación en representación vectorial, y construya la representación matricial y de conjunto de conjuntos de la clasificación. Haz un método para cada conversión:  \n",
    "    - vectorial -> matricial.  \n",
    "    - vectorial -> conjunto de conjuntos.  \n",
    "- Guarda las tres representaciones como variables ocultas usando la nomenclatura \"__parameter\".  \n",
    "- Crea tres métodos getter para devolver cada representación.  \n",
    "- Construye un método para calcular los siguientes valores:  \n",
    "    - Entropía de una clasificación.  \n",
    "    - La entropía condicional de una clasificación dada otra clasificación.  \n",
    "    - La información mutua de una clasificación dada otra clasificación.  \n",
    "    - La variación de información de una clasificación dada otra clasificación.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyClass():\n",
    "    def __init__(self, vector):\n",
    "        self.__vector = vector\n",
    "        self.__labels = self.get_labels()\n",
    "        self.__probabilities = self.get_probabilities()\n",
    "        self.__join_probabilities = self.get_join_probabilities()\n",
    "        self.__matrix = self.create_matrix()\n",
    "        self.__sets = self.create_sets()\n",
    "\n",
    "\n",
    "    def create_matrix(self):\n",
    "        # Create an empty matrix\n",
    "        matrix = []\n",
    "        for row in range(len(self.__vector)): # for each label in the vector\n",
    "            matrix.append([0] * len(self.__labels)) # add a row of zeros\n",
    "\n",
    "        # Fill the matrix\n",
    "        for label in range(len(self.__vector)): # for each label in the vector\n",
    "\n",
    "            matrix[label][self.__labels.index(self.__vector[label])] = 1 # set the value to 1\n",
    "            # labels.index(self.__vector[label]) returns the index of the label in the labels list\n",
    "\n",
    "        return matrix\n",
    "    \n",
    "\n",
    "    def create_sets(self):\n",
    "        # Create a dictionary of sets        \n",
    "        conjuntos = {} \n",
    "        for i, elemento in enumerate(self.__vector):  \n",
    "            if elemento not in conjuntos:\n",
    "                conjuntos[elemento] = set()\n",
    "            conjuntos[elemento].add(i) \n",
    "\n",
    "        lista_de_conjuntos = list(conjuntos.values())\n",
    "\n",
    "        return lista_de_conjuntos\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # ---\n",
    "    # Crea tres métodos getter para devolver cada representación. \n",
    "\n",
    "    def get_vector(self):\n",
    "        return self.__vector\n",
    "    \n",
    "    def get_matrix(self):\n",
    "        return self.__matrix\n",
    "    \n",
    "    def get_sets(self):\n",
    "        return self.__sets\n",
    "    \n",
    "    # Las usamos mucho, entonces las guardamos en variables\n",
    "    def get_labels(self):\n",
    "        labels = []\n",
    "        for label in self.__vector:\n",
    "            if label not in labels:\n",
    "                labels.append(label)\n",
    "        return labels\n",
    "    \n",
    "    def get_probabilities(self):\n",
    "        probabilities = [] \n",
    "        for label in self.__labels:\n",
    "            probability = self.__vector.count(label) / len(self.__vector) # |y_i| / N\n",
    "            probabilities.append(probability)\n",
    "    \n",
    "    # Joint probabilities\n",
    "    #\n",
    "    # Y = {{}, {1, 2, 3, 4}, {   5, 6, 7, 8}}\n",
    "    # Y'= {{}, {   2, 3, 4}, {1, 5, 6, 7, 8}}\n",
    "    # \n",
    "    # P(Y'=1|Y=1) = 3/4\n",
    "    # P(Y'=2|Y=1) = 1/4\n",
    "    # \n",
    "    # La suma de los de arriba da 1\n",
    "    #\n",
    "    # P(Y'=1|Y=2) = 0\n",
    "    # P(Y'=2|Y=2) = 1\n",
    "\n",
    "    def get_join_probabilities(self, other):\n",
    "        joint_probabilities = []\n",
    "        for i in range(len(self.__labels)):\n",
    "            for j in range(len(self.__labels)):\n",
    "                joint_probability = 0\n",
    "                for k in range(len(self.__vector)):\n",
    "                    if self.__vector[k] == self.__labels[i] and other[k] == self.__labels[j]:\n",
    "                        joint_probability += 1\n",
    "                joint_probability /= len(self.__vector)\n",
    "                joint_probabilities.append(joint_probability)\n",
    "        return joint_probabilities\n",
    "\n",
    "    \n",
    "\n",
    "    # ---\n",
    "    # Construye un método para calcular los siguientes valores:\n",
    "\n",
    "    # - Entropía de una clasificación.\n",
    "    def entropy(self):\n",
    "        \n",
    "        entropy = 0\n",
    "        for prob in self.__probabilities:\n",
    "            # lim_{p -> 0} p log_2(p) = 0\n",
    "            if prob != 0:\n",
    "                entropy += -prob * np.log2(prob)\n",
    "            else:\n",
    "                entropy += 0\n",
    "\n",
    "        print(\"Probabilities:\", self.__probabilities, \"Entropy:\", entropy)\n",
    "        return entropy\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # - La entropía condicional de una clasificación dada otra clasificación.\n",
    "    def conditional_entropy(self, other):\n",
    "        # Intersection between the two classifications\n",
    "        intersection = []\n",
    "        for i in range(len(self.__vector)):\n",
    "            if self.__vector[i] == other[i]:\n",
    "                intersection.append(self.__vector[i])\n",
    "        \n",
    "        # Calculate the probabilities p(l, l')\n",
    "        probabilities = [] # create a list of probabilities\n",
    "        for label in self.__labels: # for each label in the intersection\n",
    "            probability = intersection.count(label) / len(self.__vector) # count the number of times the label appears in the intersection\n",
    "            probabilities.append(probability)\n",
    "\n",
    "        \n",
    "        # Cuantos elementos hay en la clase y \n",
    "        joint_probabilities = []\n",
    "        for i in range(len(self.__labels)):\n",
    "            for j in range(len(self.__labels)):\n",
    "                joint_probability = 0\n",
    "                for k in range(len(self.__vector)):\n",
    "                    if self.__vector[k] == self.__labels[i] and other[k] == self.__labels[j]:\n",
    "                        joint_probability += 1\n",
    "                joint_probability /= len(self.__vector)\n",
    "                joint_probabilities.append(joint_probability) # - Chat\n",
    "\n",
    "        # Calculate the conditional entropy\n",
    "        conditional_entropy = 0\n",
    "        for prob in probabilities:\n",
    "            # lim_{p -> 0} p log_2(p) = 0\n",
    "            if prob != 0:\n",
    "                joint = joint_probabilities[probabilities.index(prob)] / prob  # - Chat\n",
    "                conditional_entropy += -prob * np.log2(joint)\n",
    "            else:\n",
    "                conditional_entropy += 0\n",
    "\n",
    "        print(\"Intersection:\", intersection, \"Probabilities:\", probabilities, \"N:\", len(self.__vector), \"Conditional Entropy:\", conditional_entropy)\n",
    "        \n",
    "        return conditional_entropy\n",
    "\n",
    "    \n",
    "    \n",
    "    # - La información mutua de una clasificación dada otra clasificación.\n",
    "    def mutual_information(self, other):\n",
    "        # 2 equalit: I(y, x)= H(y) - H(y| x)\n",
    "        mutual_information = self.entropy() - self.conditional_entropy(other)\n",
    "        print(\"Mutual Information 1:\", mutual_information)\n",
    "\n",
    "        # 1 equality: I(y, x)= sum_{y in Y} sum_{x in X} p(y, x) log_2(p(y, x) / (p(y) * p(x)))\n",
    "\n",
    "        # Calculate the joint probabilities\n",
    "        joint_probabilities = []\n",
    "        for i in range(len(self.__labels)):\n",
    "            for j in range(len(self.__labels)):\n",
    "                joint_probability = 0\n",
    "                for k in range(len(self.__vector)):\n",
    "                    if self.__vector[k] == self.__labels[i] and other[k] == self.__labels[j]:\n",
    "                        joint_probability += 1\n",
    "                joint_probability /= len(self.__vector)\n",
    "                joint_probabilities.append(joint_probability) # - Chat\n",
    "\n",
    "        # Calculate the mutual information\n",
    "        mutual_information = 0\n",
    "        for i in range(len(self.__labels)):\n",
    "            for j in range(len(self.__labels)):\n",
    "                if joint_probabilities[i * len(self.__labels) + j] != 0:\n",
    "                    mutual_information += joint_probabilities[i * len(self.__labels) + j] * np.log2(joint_probabilities[i * len(self.__labels) + j] / (probabilities[i] * probabilities[j])) # - Chat\n",
    "\n",
    "        print(\"Mutual Information 2:\", mutual_information, \"Probabilities:\", probabilities, \"Joint Probabilities:\", joint_probabilities)\n",
    "        \n",
    "        return mutual_information\n",
    "    \n",
    "    # - La variación de información de una clasificación dada otra clasificación. \n",
    "\n",
    "    def variation_of_information(self, other):\n",
    "        # VI(x, y) = H(y) + H(x) - 2I(y, x)\n",
    "        variation_of_information = self.entropy() + self.entropy() - 2 * self.mutual_information(other)\n",
    "        print(\"Variation of Information:\", variation_of_information)\n",
    "\n",
    "        return variation_of_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = (0, 0, 0, 1, 1, 1, 2, 2, 2)\n",
    "other =  (1, 1, 1, 1, 1, 1, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_class = MyClass(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.create_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.get_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 1, 2}, {3, 4, 5}, {6, 7, 8}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.create_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 1, 2}, {3, 4, 5}, {6, 7, 8}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = (0, 0, 0, 1, 1, 1, 2, 2, 2)\n",
    "my_class.get_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Entropy: 1.584962500721156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection: [0, 0, 0, 1, 1, 1, 2, 2, 2] Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] N: 9 Conditional Entropy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.conditional_entropy(vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection: [1, 1, 1] Probabilities: [0.0, 0.3333333333333333, 0.0] N: 9 Conditional Entropy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.conditional_entropy(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Entropy: 1.584962500721156\n",
      "Intersection: [0, 0, 0, 1, 1, 1, 2, 2, 2] Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] N: 9 Conditional Entropy: 0.0\n",
      "Mutual Information 1: 1.584962500721156\n",
      "Mutual Information 2: 1.5849625007211559 Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Joint Probabilities: [0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5849625007211559"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.mutual_information(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Entropy: 1.584962500721156\n",
      "Intersection: [1, 1, 1] Probabilities: [0.0, 0.3333333333333333, 0.0] N: 9 Conditional Entropy: 0.0\n",
      "Mutual Information 1: 1.584962500721156\n",
      "Mutual Information 2: 1.5849625007211559 Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Joint Probabilities: [0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5849625007211559"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.mutual_information(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Entropy: 1.584962500721156\n",
      "Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Entropy: 1.584962500721156\n",
      "Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Entropy: 1.584962500721156\n",
      "Intersection: [0, 0, 0, 1, 1, 1, 2, 2, 2] Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] N: 9 Conditional Entropy: 0.0\n",
      "Mutual Information 1: 1.584962500721156\n",
      "Mutual Information 2: 1.5849625007211559 Probabilities: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Joint Probabilities: [0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333]\n",
      "Variation of Information: 4.440892098500626e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.440892098500626e-16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.variation_of_information(vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
