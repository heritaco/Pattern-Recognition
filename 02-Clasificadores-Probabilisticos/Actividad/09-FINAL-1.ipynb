{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# la Resting ECG de la clase dos es bernoulli! y la estamos tratando como multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Es mejor que cada una tenga su distribucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, bernoulli, multinomial, gaussian_kde, shapiro, kstest, poisson\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleavland = pd.read_csv('05-heart+disease/processed.cleveland.data', header=None, encoding='ISO-8859-1')\n",
    "hungary = pd.read_csv('05-heart+disease/processed.hungarian.data', header=None, encoding='ISO-8859-1')\n",
    "switzerland = pd.read_csv('05-heart+disease/processed.switzerland.data', header=None, encoding='ISO-8859-1')\n",
    "va = pd.read_csv('05-heart+disease/processed.va.data', header=None, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"Age\", \"Sex\", \"Chest Pain Type\", \"Resting Blood Pressure\", \"Cholesterol\", \"Fasting Blood Sugar\", \"Resting ECG\", \"Max Heart Rate\", \"Exercise Induced Angina\", \"ST Depression\", \"Slope\", \"Number of Major Vessels\", \"Thal\", \"Diagnosis of Heart Disease\"]\n",
    "\n",
    "cleavland.columns = attributes\n",
    "hungary.columns = attributes\n",
    "switzerland.columns = attributes\n",
    "va.columns = attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([cleavland, hungary, switzerland, va], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "# sort df by class, later the Iwi[i] will be sorted by this order\n",
    "df = df.sort_values(by=[df.columns[-1]])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(df):\n",
    "    \n",
    "    classes = df.iloc[:, -1].unique() # M\n",
    "    total = len(df)                   # N\n",
    "    attributes = df.columns           # X_i i \\in {1, 2, ...}\n",
    "\n",
    "    Iwi = []        # Table of instances for each class\n",
    "    pwi = []        # a priori probability\n",
    "    pxjIwi = []     # p(X_j|w_i) for each class\n",
    "\n",
    "    for i in range(len(classes)):                   # For every class\n",
    "\n",
    "        Iwi.append(df[df.iloc[:, -1] == classes[i]])         # Append the instances of the class\n",
    "        pwi.append(len(Iwi[i])/total)               # Append the a priori probability\n",
    "        \n",
    "        pxjIwi.append([])                           # Append an empty list for the conditional probability - chat\n",
    "\n",
    "        for attribute in attributes[:-1]:        # For every attribute except the last one (target variable)\n",
    "\n",
    "            unique_values = Iwi[i][attribute].unique()\n",
    "\n",
    "            # Poisson distribution\n",
    "            if len(unique_values) < 10:\n",
    "            # Test if the attribute is Poisson distributed\n",
    "                mean = Iwi[i][attribute].mean()\n",
    "                ks_test = kstest(Iwi[i][attribute], 'poisson', args=(mean,))    # - test if the attribute is Poisson distributed\n",
    "                if ks_test.pvalue > 0.05:\n",
    "                    lambda_ = Iwi[i][attribute].mean()  # Calculate the mean\n",
    "                    un_pxiIwi = poisson(lambda_)            # Create a Poisson distribution\n",
    "\n",
    "            # Multinomial distribution\n",
    "\n",
    "            # Normal distribution\n",
    "            else: \n",
    "                shapiro_test = shapiro(Iwi[i][attribute])\n",
    "                if shapiro_test.pvalue > 0.05:\n",
    "                    xbar = Iwi[i][attribute].mean()\n",
    "                    s = Iwi[i][attribute].std()\n",
    "                    un_pxiIwi = norm(xbar, s)             # Create a Normal distribution\n",
    "\n",
    "            # KDE distribution\n",
    "                else:\n",
    "                    un_pxiIwi = gaussian_kde(Iwi[i][attribute]) # Calculate the probability\n",
    "\n",
    "            pxjIwi[i].append(un_pxiIwi)                    # Append the conditional probability\n",
    "\n",
    "    return pxjIwi, pwi, Iwi, classes, attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_categorical(attribute, value, Iwi):\n",
    "    exitoIwi = len(Iwi[Iwi[attribute] == value])\n",
    "    nIwi = len(Iwi)\n",
    "    p = exitoIwi/nIwi\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostic(age, sex, chest_pain_type, resting_blood_pressure, cholesterol, fasting_blood_sugar, resting_ecg, max_heart_rate, exercise_induced_angina, st_depression, slope, number_of_major_vessels, thal):\n",
    "\n",
    "    pxjIwi, pwi, Iwi, classes, attributes = get_distribution(df)\n",
    "\n",
    "    Pwis = []\n",
    "\n",
    "    for clase in range(len(classes)):\n",
    "\n",
    "        # Tienen que ir adentro porque los de la clase 3 no tienen Chest Pain Type 1\n",
    "\n",
    "        Page = pxjIwi[clase][0].pdf(age)\n",
    "        Psex = probability_categorical(\"Sex\", sex, Iwi[clase])\n",
    "        Pcpt = probability_categorical(\"Chest Pain Type\", chest_pain_type, Iwi[clase])\n",
    "        Prbp = pxjIwi[clase][3].pdf(resting_blood_pressure)\n",
    "        Pcho = pxjIwi[clase][4].pdf(cholesterol)\n",
    "        Pfbs = probability_categorical(\"Fasting Blood Sugar\", fasting_blood_sugar, Iwi[clase])\n",
    "        Prec = probability_categorical(\"Resting ECG\", resting_ecg, Iwi[clase])\n",
    "        Pmhr = pxjIwi[clase][7].pdf(max_heart_rate)\n",
    "        Peia = probability_categorical(\"Exercise Induced Angina\", exercise_induced_angina, Iwi[clase])\n",
    "        Pstd = pxjIwi[clase][9].pdf(st_depression)\n",
    "        Pslo = probability_categorical(\"Slope\", slope, Iwi[clase])\n",
    "        Pnmv = probability_categorical(\"Number of Major Vessels\", number_of_major_vessels, Iwi[clase])\n",
    "        # Ptal = pxjIwi[clase][12].evaluate(thal)\n",
    "        \n",
    "        Pwi = pwi[clase] * Page * Psex * Pcpt * Prbp * Pcho * Pfbs * Prec * Pmhr * Peia * Pstd * Pslo * Pnmv # * Ptal\n",
    "\n",
    "        if type(Pwi) == np.ndarray:\n",
    "            Pwi = Pwi[0]\n",
    "        Pwis.append(Pwi)\n",
    "\n",
    "        # print(f\"Diagnosis of heart disease {clase} is {Pwi}\")\n",
    "\n",
    "    argmax = np.argmax(Pwis)\n",
    "    print(f\"The most likely diagnosis is {argmax}\")\n",
    "\n",
    "    return argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(df):\n",
    "    pxjIwi, pwi, Iwi, classes, attributes = get_distribution(df)\n",
    "\n",
    "    for clase in range(len(classes)):\n",
    "        Iwi[clase] = Iwi[clase].sample(frac=1).reset_index(drop=True)   # Shuffle the rows\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    for clase in range(len(classes)):\n",
    "        train.append(Iwi[clase].iloc[:  int(len(Iwi[clase])*0.8), :])   # 80% of the rows\n",
    "        test.append(Iwi[clase].iloc[int(len(Iwi[clase])*0.8):, :])      # 20% of the rows\n",
    "\n",
    "    df = pd.concat([train[0], train[1], train[2], train[3], train[4]], ignore_index=True)\n",
    "\n",
    "    dist2 = get_distribution(df)\n",
    "\n",
    "    diagnostic(*test[0].iloc[0, :-1]) # chat. The * unpacks the values of the row, so it's like diagnostic(test[0].iloc[0, 0], test[0].iloc[0, 1], ...)\n",
    "\n",
    "    alltest = pd.concat([test[0], test[1], test[2], test[3], test[4]], ignore_index=True)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(len(alltest)):\n",
    "        predictpredict = diagnostic(*alltest.iloc[i, :-1])\n",
    "        predictions.append(predictpredict)\n",
    "\n",
    "    # add the predictions to the dataframe\n",
    "    alltest[\"PREDICT PREDICT\"] = predictions\n",
    "\n",
    "    return alltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(df):\n",
    "\n",
    "    alltest = cross_validation(df)\n",
    "    # True labels\n",
    "    y_true = alltest.iloc[:, -2] \n",
    "\n",
    "    # Predicted labels\n",
    "    y_pred = alltest.iloc[:, -1]\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1, 2, 3, 4])\n",
    "    disp.plot(cmap=\"OrRd\", ax=ax, colorbar=False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Balanced accuracy\n",
    "    metrics.balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Precision\n",
    "    metrics.precision_score(y_true, y_pred,\n",
    "                            average=None)\n",
    "\n",
    "    # Recall\n",
    "    metrics.recall_score(y_true, y_pred,\n",
    "                        average=None)\n",
    "\n",
    "    # F1-score\n",
    "    metrics.f1_score(y_true, y_pred,\n",
    "                    average=None)\n",
    "\n",
    "\n",
    "    #F-beta score\n",
    "    beta_1 = metrics.fbeta_score(y_true, y_pred,\n",
    "                        average=None,\n",
    "                        beta=1)\n",
    "    beta_2 = metrics.fbeta_score(y_true, y_pred,\n",
    "                        average=None,\n",
    "                        beta=.1)\n",
    "    print(\"beta=1\", beta_1)\n",
    "    print(\"beta=2\", beta_2)\n",
    "\n",
    "    # Display classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
